
write about:



test:



on hold:


to do:
    MIL / agg methods / pooling
    write a summary about the innovation in CIN/GS
    research proposal extension - write to moti?
    move to to other biomarks


init model
weighted loss symmetry ce loss
logging
lr and decaying of stuff / warmups
adaptor - used

loading to from cuda

inference boostraps - on hold




optimizer params - batch size
teacher momentum + batch size
teacher temp
weight decay
lr temp
frozen last layer
norm_last_layer
DINOHead dim












runs -
other -


general -
train and test on another cohort
Billal label files - do same logic for STAD/UCEC? - Yossi said - not makes sense
CPTAC is publicly available
Wang et al. trained the network using an unsupervised
contrastive loss on data from TCGA and PAIP36 from multiple organs and provided the weights for public use. The embeddings
for each tile are stored for the subsequent training procedure







thinking:
look at the cleaning phases of Cell and the paper about UCEC


future:
3/5 CV - on all results before submission
testing on OOD dataset - could be a potential for improvement.
Using pretrained HIPT?


Questions:


comments:
    blur slides - not correlated to AUC
    slides mistakes  - looks pretty similar
    lightly?
    slide aware network? using positional encoding?