
write about:



test:



on hold:

to do:

    runs:
    tile based classic - train and test + imagenet
    ABMIL
    rerun distilmill with proper warmup


    CIN gs
    1. End presentation
    2. try abmil
    3. try tile based for regular (to show diff)
    Questions:
    1. is it enough for iccv
    2. More dataset to fuse


    Variant:
    3. create df_auc for all
    2. Create the Analysis
    3. summarize in presentation
    Question:
    1.


    try each cohort on its on
    check for slide detection from the tier1/2
    tune epochs/bags





    repeat the entire process again....
    check other papers for slide canceling

    accumolate gradients?
    tile weight?
    MLH instead of gated attention?
    warmup slide head? - move to slide level and global level
    trainable backbone? + warmup
    add slide loss
    epochs?

    gradient clip?
    weight decay?

    plot again and see diff in the heatmaps





    move to tanh


    # rotating validation sets - train test reduce ect




    consider pretrain using all and train only using single cohort - in that way you don't increase the number of training sample - could be very interesting
    tune on single cohort

    move to other biomarks



runs -
other -


general -
train and test on another cohort
Billal label files - do same logic for STAD/UCEC? - Yossi said - not makes sense
CPTAC is publicly available
Wang et al. trained the network using an unsupervised
contrastive loss on data from TCGA and PAIP36 from multiple organs and provided the weights for public use. The embeddings
for each tile are stored for the subsequent training procedure

understand the FoVs - some slides are big with low number of tiles (different Fovs?), does the cell oval size is the same size in all images? (or other common something)
some of the slide has weird tiling - single tile for something that look normal.. (not in labels..)







thinking:
look at the cleaning phases of Cell and the paper about UCEC


future:
3/5 CV - on all results before submission
testing on OOD dataset - could be a potential for improvement.
Using pretrained HIPT?
add more FoVs? like 384 and 786?


Questions:


comments:
    blur slides - not correlated to AUC
    slides mistakes  - looks pretty similar
    lightly?
    slide aware network?
    using positional encoding - not gonna work.